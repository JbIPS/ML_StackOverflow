{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6422dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans, DBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation, NMF\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from kneed import KneeLocator\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0670edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uiimageview later uiimageview uiimageview cell...</td>\n",
       "      <td>[iphone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>requirement againstabout people traditional al...</td>\n",
       "      <td>[c#, winforms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gem rake parse content dump character cause crash</td>\n",
       "      <td>[ruby, xml]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>includes nested primary link sub straight exac...</td>\n",
       "      <td>[php]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>searching django stuff django struggling searc...</td>\n",
       "      <td>[python, sql, django]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75358</th>\n",
       "      <td>rid vector ptr vector removed deleted obvious ...</td>\n",
       "      <td>[c++]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75359</th>\n",
       "      <td>singleton factory domain factory</td>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75360</th>\n",
       "      <td>resharper removing directive perhaps configura...</td>\n",
       "      <td>[c#, visual-studio-2008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75361</th>\n",
       "      <td>started document developing apps iphone wanted...</td>\n",
       "      <td>[iphone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75362</th>\n",
       "      <td>area dot distributed area detect cluster dot a...</td>\n",
       "      <td>[algorithm]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75363 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Body  \\\n",
       "0      uiimageview later uiimageview uiimageview cell...   \n",
       "1      requirement againstabout people traditional al...   \n",
       "2      gem rake parse content dump character cause crash   \n",
       "3      includes nested primary link sub straight exac...   \n",
       "4      searching django stuff django struggling searc...   \n",
       "...                                                  ...   \n",
       "75358  rid vector ptr vector removed deleted obvious ...   \n",
       "75359                   singleton factory domain factory   \n",
       "75360  resharper removing directive perhaps configura...   \n",
       "75361  started document developing apps iphone wanted...   \n",
       "75362  area dot distributed area detect cluster dot a...   \n",
       "\n",
       "                           Tags  \n",
       "0                      [iphone]  \n",
       "1                [c#, winforms]  \n",
       "2                   [ruby, xml]  \n",
       "3                         [php]  \n",
       "4         [python, sql, django]  \n",
       "...                         ...  \n",
       "75358                     [c++]  \n",
       "75359                    [java]  \n",
       "75360  [c#, visual-studio-2008]  \n",
       "75361                  [iphone]  \n",
       "75362               [algorithm]  \n",
       "\n",
       "[75363 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./cleaned_dataset.csv', converters={'Tags': lambda x: eval(x)})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625d4e5",
   "metadata": {},
   "source": [
    "# Vectorizing data\n",
    "\n",
    "Plusieurs méthodes nous permettent de transformer ce bag-of-words en données numérique. Nous allons créer une fonction de preprocessing permettant de la choisir, afin de les tester de manières indépendantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1334e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algorithm(Enum):\n",
    "    KMeans = 'kmeans'\n",
    "    MiniBatchKmeans = 'minikmeans'\n",
    "    DBSCAN = 'dbscan'\n",
    "\n",
    "\n",
    "class Vectorizer(Enum):\n",
    "    Count = 'count'\n",
    "    TfIdf = 'tf-idf'\n",
    "\n",
    "\n",
    "def preprocessing(dataset: pd.DataFrame, vectorizer: Vectorizer):\n",
    "    \"\"\" Add features engineering to the dataset \"\"\"\n",
    "    max_features = 3000\n",
    "\n",
    "    # CountVectorizer\n",
    "    if vectorizer == Vectorizer.Count:\n",
    "        count_vectorizer = CountVectorizer(lowercase=False, max_features=max_features)\n",
    "        count_matrix = count_vectorizer.fit_transform(dataset['Body'])\n",
    "        df = pd.DataFrame(count_matrix.toarray(), index=dataset.index,\n",
    "                          columns=count_vectorizer.get_feature_names_out())\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Tf-Idf\n",
    "    elif vectorizer == Vectorizer.TfIdf:\n",
    "        tf_vectorizer = TfidfVectorizer(lowercase=False, max_features=max_features, ngram_range=(1,2))\n",
    "        tf_matrix = tf_vectorizer.fit_transform(dataset['Body'])\n",
    "        df = pd.DataFrame(tf_matrix.toarray(), index=dataset.index,\n",
    "                          columns=tf_vectorizer.get_feature_names_out())\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    n_components = 1000\n",
    "    pca = PCA(n_components=n_components)\n",
    "    df_projected = pca.fit_transform(df)\n",
    "    return (df_projected, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be52e0d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectors = {name: preprocessing(dataset, vectorizer) for name, vectorizer in Vectorizer.__members__.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e74c5",
   "metadata": {},
   "source": [
    "# Unsupervized clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d292713e",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "Pour ce test, nous utiliserons la version `MiniBatchKMeans` qui donne des résultats similaires mais permet une exécution beaucoup plus rapide. Nous passerons sur KMeans pour la production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfe906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clusters(X):\n",
    "    kelbow_viz = KElbowVisualizer(MiniBatchKMeans(random_state=5), k=(16, 24))\n",
    "    kelbow_viz.fit(X)\n",
    "    kelbow_viz.show()\n",
    "    print(f'kelbow: {kelbow_viz.elbow_value_}')\n",
    "\n",
    "    kmeans = MiniBatchKMeans(kelbow_viz.elbow_value_, random_state=5)\n",
    "    kmeans.fit(X)\n",
    "    labels = pd.Series(kmeans.labels_, name='cluster-label')\n",
    "    value_dict = dict(labels.value_counts())\n",
    "    value_counts = {str(k): int(v) for k, v in value_dict.items()}\n",
    "    display(pd.Series(value_counts, name='clusters-size'))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b15ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_labels = {}\n",
    "for name, vector in vectors.items():\n",
    "    print(f'KMeans with {name}')\n",
    "    start = time.time()\n",
    "    kmeans_labels[name] = kmeans_clusters(vector[0])\n",
    "    print(f'Execution time: {time.time() - start}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eaa570",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfe0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def get_top_tags(df, label, nb_tags=5):\n",
    "    tagsFreq = df[df['cluster_label'] == label]['tags'].to_frame().apply(lambda x : pd.Series([x['tags'], nltk.FreqDist(x['tags'])], index=['tokens', 'frequency']), axis=1, result_type='expand')\n",
    "    total_freq = {}\n",
    "    for dictionnary in tagsFreq['frequency']:\n",
    "        for k,v in dictionnary.items():\n",
    "            if k in total_freq:\n",
    "                total_freq[k] += v\n",
    "            else:\n",
    "                total_freq[k] = v\n",
    "\n",
    "    freq_list = sorted(total_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    return freq_list[:nb_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0fe01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "n_cols = 2\n",
    "n_rows = max([serie.max() for serie in kmeans_labels.values()]) + 1\n",
    "fig = plt.figure(constrained_layout=True, figsize=(n_cols * 10 , n_rows * 5))\n",
    "subfigures = fig.subfigures(1, len(kmeans_labels))\n",
    "for vect_idx, (name, label) in enumerate(kmeans_labels.items()):\n",
    "    dataset_labels = vectors[name][1].assign(cluster_label=label,\n",
    "                           tags=dataset['Tags'])\n",
    "    cluster_sum = dataset_labels.groupby('cluster_label').sum()\n",
    "    subfigures[vect_idx].suptitle(name, fontsize='xx-large')\n",
    "    for label_idx, label in enumerate(cluster_sum.index):\n",
    "        top10_topics = cluster_sum.loc[label]\\\n",
    "                .sort_values(ascending=False)\\\n",
    "                .head(10).index.to_list()\n",
    "        ax = subfigures[vect_idx].add_subplot(n_rows, 1, label_idx + 1)\n",
    "        ax.set_title(f'Topic {label}', fontsize='xx-large')\n",
    "        cloud = WordCloud().generate(' '.join(top10_topics))\n",
    "        ax.imshow(cloud, interpolation='bilinear')\n",
    "        ax.grid(False)\n",
    "        ax.tick_params(axis='both', left=False, bottom=False, labelbottom=False, labelleft=False)\n",
    "        ax.set_xlabel(' '.join([f'{tag} ({count})' for (tag, count) in get_top_tags(dataset_labels, label)]), fontsize='x-large')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f0acd",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70161894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "for (name, vector), (_, labels) in zip(vectors.items(), kmeans_labels.items()):\n",
    "    print(f'{name} Silhouette score : {silhouette_score(vector[0], labels)}')\n",
    "    print(f'{name} Calinski-Harabasz score : {calinski_harabasz_score(vector[0], labels)}')\n",
    "    print(f'{name} Davies-Bouldin score : {davies_bouldin_score(vector[0], labels)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35398ac",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dbscan_clusters(X):\n",
    "    # Need to sample to avoid too much resources comsuption\n",
    "    X_sample = X[0:30000]\n",
    "    nb_neighbors = 10\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=nb_neighbors)\n",
    "    nearest_neighbors.fit(X_sample)\n",
    "    distances, _ = nearest_neighbors.kneighbors(X_sample)\n",
    "\n",
    "    # Get max distance between neighbors\n",
    "    max_distances = np.sort(distances[:, nb_neighbors - 1])\n",
    "\n",
    "    # Find an elbow\n",
    "    index = np.arange(len(max_distances))\n",
    "    knee = KneeLocator(index, max_distances, curve='convex',\n",
    "                       direction='increasing', interp_method='polynomial')\n",
    "    knee.plot_knee(figsize=(10, 10))\n",
    "    plt.xlabel(\"Points\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()\n",
    "\n",
    "    dbscan = DBSCAN(min_samples=100, eps=knee.elbow_y)\n",
    "    dbscan.fit(X_sample)\n",
    "    print(f'Nombre de clusters : {len(dbscan.labels_)}')\n",
    "    labels = pd.Series(dbscan.labels_, name='cluster-label')\n",
    "    value_dict = dict(labels.value_counts())\n",
    "    value_counts = {str(k): int(v) for k, v in value_dict.items()}\n",
    "    display(pd.Series(value_counts, name='clusters-size'))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_labels = {}\n",
    "for name, vector in vectors.items():\n",
    "    print(f'DBSCAN with {name}')\n",
    "    dbscan_labels[name] = make_dbscan_clusters(vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce34639",
   "metadata": {},
   "source": [
    "DBSCAN ne semble pas à l'aise avec ces données et nécessite une puissance bien plus grande que KMeans. Nous allons donc le laisser de côté."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0c7c3",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9251182",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fix the number of topics near the KMeans elbow\n",
    "no_topics = 17\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online',\n",
    "                                         learning_offset=50., random_state=0).fit(vectors['Count'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233d569",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb4d7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    cloud = WordCloud().generate(\" \".join([vectors['Count'][1].columns[i]\n",
    "                    for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    plt.imshow(cloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Topic {topic_idx}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e086c7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Log-likelihood: {lda.score(vectors[\"Count\"][1])}')\n",
    "print(f'Perplexity: {lda.perplexity(vectors[\"Count\"][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e162f2",
   "metadata": {},
   "source": [
    "# Supervized clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d95e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 30000\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors['Count'][0][:sample], dataset['Tags'].iloc[:sample], test_size=0.2, random_state=34)\n",
    "\n",
    "mlb = MultiLabelBinarizer().fit(dataset['Tags'].iloc[:sample].to_list())\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ovr = OneVsRestClassifier(LogisticRegression(n_jobs=-1, max_iter=500), n_jobs=-1)\n",
    "ovr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98572ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ovr_score = ovr.score(X_test, y_test)\n",
    "ovr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ovr = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1), n_jobs=-1)\n",
    "ovr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11805af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ovr_score = ovr.score(X_test, y_test)\n",
    "ovr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "ovr = OneVsRestClassifier(estimator=GradientBoostingClassifier(), n_jobs=-1)\n",
    "ovr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ovr_score = ovr.score(X_test, y_test)\n",
    "ovr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "multi = MultiOutputClassifier(KNeighborsClassifier(n_jobs=-1), n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "multi.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b5655e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors['TfIdf'][1], dataset['Tags'], test_size=0.2, random_state=34)\n",
    "\n",
    "mlb = MultiLabelBinarizer().fit(dataset['Tags'].to_list())\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3abfa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier(estimator=MultinomialNB())\n",
      "0.08744111988323493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "ovr = OneVsRestClassifier(MultinomialNB())\n",
    "print(ovr)\n",
    "ovr.fit(X_train, y_train)\n",
    "score = ovr.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed06bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 21s, sys: 4.92 s, total: 28min 26s\n",
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502b0852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19392290851190871"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902643e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089ce983",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, \u001b[43my_pred\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a97813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3660966742964858"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a950eff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3962196745802345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=1e-5, penalty='l1'), n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6152ee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.net', 'ajax', 'algorithm', 'android', 'arrays', 'asp.net',\n",
       "       'asp.net-mvc', 'c', 'c#', 'c++', 'css', 'database', 'django',\n",
       "       'eclipse', 'excel', 'html', 'ios', 'iphone', 'java', 'javascript',\n",
       "       'jquery', 'linq', 'linux', 'macos', 'multithreading', 'mysql',\n",
       "       'objective-c', 'oracle', 'performance', 'php', 'python', 'regex',\n",
       "       'ruby', 'ruby-on-rails', 'security', 'sql', 'sql-server', 'string',\n",
       "       'svn', 'unit-testing', 'user-interface', 'vb.net', 'visual-studio',\n",
       "       'visual-studio-2008', 'web-services', 'winapi', 'windows',\n",
       "       'winforms', 'wpf', 'xml'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c45dd31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "              .net       0.46      0.08      0.14      1338\n",
      "              ajax       0.42      0.10      0.17       174\n",
      "         algorithm       0.67      0.26      0.37       171\n",
      "           android       0.85      0.54      0.66       472\n",
      "            arrays       0.71      0.07      0.14       201\n",
      "           asp.net       0.78      0.27      0.40       997\n",
      "       asp.net-mvc       0.67      0.27      0.39       269\n",
      "                 c       0.61      0.26      0.36       379\n",
      "                c#       0.65      0.24      0.35      2282\n",
      "               c++       0.76      0.33      0.46       921\n",
      "               css       0.77      0.36      0.49       449\n",
      "          database       0.36      0.05      0.09       340\n",
      "            django       0.90      0.67      0.77       167\n",
      "           eclipse       0.52      0.08      0.13       155\n",
      "             excel       0.83      0.60      0.70       126\n",
      "              html       0.66      0.13      0.21       694\n",
      "               ios       0.46      0.19      0.27       159\n",
      "            iphone       0.80      0.54      0.64       473\n",
      "              java       0.78      0.49      0.60      1478\n",
      "        javascript       0.64      0.25      0.36      1241\n",
      "            jquery       0.73      0.37      0.49       683\n",
      "              linq       0.71      0.43      0.53       169\n",
      "             linux       0.66      0.29      0.40       235\n",
      "             macos       0.70      0.22      0.33       147\n",
      "    multithreading       0.64      0.43      0.51       180\n",
      "             mysql       0.62      0.14      0.23       519\n",
      "       objective-c       0.52      0.24      0.33       247\n",
      "            oracle       0.77      0.60      0.67       176\n",
      "       performance       0.54      0.20      0.29       190\n",
      "               php       0.78      0.28      0.41      1104\n",
      "            python       0.76      0.32      0.45       912\n",
      "             regex       0.85      0.56      0.67       228\n",
      "              ruby       0.52      0.11      0.18       297\n",
      "     ruby-on-rails       0.87      0.57      0.69       317\n",
      "          security       0.42      0.09      0.15       159\n",
      "               sql       0.53      0.12      0.20       645\n",
      "        sql-server       0.66      0.21      0.32       518\n",
      "            string       0.22      0.04      0.06       187\n",
      "               svn       0.84      0.75      0.79       146\n",
      "      unit-testing       0.68      0.51      0.58       150\n",
      "    user-interface       0.44      0.08      0.13       141\n",
      "            vb.net       0.67      0.33      0.45       254\n",
      "     visual-studio       0.32      0.07      0.11       286\n",
      "visual-studio-2008       0.57      0.02      0.04       211\n",
      "      web-services       0.60      0.19      0.29       171\n",
      "            winapi       0.46      0.06      0.11       175\n",
      "           windows       0.45      0.07      0.13       393\n",
      "          winforms       0.56      0.23      0.32       244\n",
      "               wpf       0.88      0.65      0.75       271\n",
      "               xml       0.69      0.17      0.27       292\n",
      "\n",
      "         micro avg       0.70      0.28      0.40     22133\n",
      "         macro avg       0.64      0.28      0.37     22133\n",
      "      weighted avg       0.66      0.28      0.38     22133\n",
      "       samples avg       0.34      0.30      0.30     22133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbrichardet/Documents/workspace/machine_learning/PStack/.venv-p5/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbff05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "model = Pipeline([\n",
    "    # ADD lemmisation\n",
    "    ('td-idf', TfidfVectorizer(lowercase=False, max_features=3000, ngram_range=(1,2))),\n",
    "    ('pca', TruncatedSVD(n_components=500, random_state=12)), # supports sparse matrix\n",
    "    ('svc', OneVsRestClassifier(SGDClassifier(loss='log', alpha=1e-5, penalty='l1', random_state=9), n_jobs=-1))\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['Body'], dataset['Tags'], test_size=0.2, random_state=5)\n",
    "mlb = MultiLabelBinarizer().fit(dataset['Tags'].to_list())\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb325a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31795919805503686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.04      0.07      1286\n",
      "           1       0.50      0.04      0.07       198\n",
      "           2       0.68      0.28      0.40       175\n",
      "           3       0.85      0.39      0.54       473\n",
      "           4       0.67      0.09      0.16       201\n",
      "           5       0.80      0.19      0.31       949\n",
      "           6       0.65      0.10      0.17       245\n",
      "           7       0.53      0.21      0.30       409\n",
      "           8       0.68      0.15      0.25      2189\n",
      "           9       0.78      0.26      0.39       966\n",
      "          10       0.77      0.27      0.40       448\n",
      "          11       0.45      0.03      0.05       333\n",
      "          12       0.89      0.60      0.72       167\n",
      "          13       0.25      0.02      0.04       158\n",
      "          14       0.78      0.55      0.65       148\n",
      "          15       0.58      0.09      0.16       636\n",
      "          16       0.32      0.17      0.22       142\n",
      "          17       0.84      0.45      0.59       479\n",
      "          18       0.86      0.31      0.45      1564\n",
      "          19       0.66      0.19      0.30      1268\n",
      "          20       0.70      0.24      0.36       692\n",
      "          21       0.68      0.32      0.43       146\n",
      "          22       0.65      0.27      0.39       251\n",
      "          23       0.63      0.18      0.28       146\n",
      "          24       0.60      0.33      0.43       165\n",
      "          25       0.60      0.07      0.13       500\n",
      "          26       0.55      0.27      0.36       245\n",
      "          27       0.81      0.52      0.63       192\n",
      "          28       0.55      0.16      0.24       218\n",
      "          29       0.69      0.14      0.23      1134\n",
      "          30       0.65      0.17      0.27       931\n",
      "          31       0.86      0.59      0.70       207\n",
      "          32       0.43      0.10      0.17       292\n",
      "          33       0.90      0.53      0.66       337\n",
      "          34       0.50      0.04      0.07       171\n",
      "          35       0.49      0.12      0.19       640\n",
      "          36       0.58      0.14      0.22       502\n",
      "          37       0.25      0.01      0.02       170\n",
      "          38       0.93      0.66      0.77       171\n",
      "          39       0.72      0.40      0.51       172\n",
      "          40       0.62      0.06      0.10       141\n",
      "          41       0.74      0.31      0.43       264\n",
      "          42       0.47      0.03      0.05       279\n",
      "          43       0.57      0.02      0.04       196\n",
      "          44       0.73      0.21      0.33       167\n",
      "          45       0.38      0.05      0.09       148\n",
      "          46       0.46      0.03      0.05       381\n",
      "          47       0.60      0.15      0.23       227\n",
      "          48       0.87      0.65      0.75       266\n",
      "          49       0.67      0.17      0.27       272\n",
      "\n",
      "   micro avg       0.71      0.20      0.32     22057\n",
      "   macro avg       0.64      0.23      0.31     22057\n",
      "weighted avg       0.66      0.20      0.30     22057\n",
      " samples avg       0.26      0.22      0.23     22057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbrichardet/Documents/workspace/machine_learning/PStack/.venv-p5/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f23790c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post: programmer year total professionally little company developer began day benefit databinding query directly querying manually adding approach generally considered cleaner simpler term deploying case manually adding grained asking assigned bug deal populate love clean unnecessary logic push library\n",
      "Prediction: [()]\n",
      "True Labels: [('.net', 'c#', 'sql-server')]\n",
      "Post: implementing nhibernate existing process bulk inserting updating nhibernate aware occurring backend initiated nhibernate nhibernate mentioned storing httpcontext callcontext duration lifecycle implemented afraid cost initializing nhibernate significant performance hit approach initializing sense sessionfactory httpcontext callcontext mapping regenerated\n",
      "Prediction: [()]\n",
      "True Labels: [('asp.net',)]\n",
      "Post: sketch nx sketch sketch geometric shape customer sketch supposed serve cross section sketch supposed extrude written purpose gap believe sketch yet gap kindly tell written gap sketch thank strict offimports systemimports nxopenmodule point sub byval args declare nx dim thesession getsession dim workpart thesession part section dim circ nxopen section workpart section createsection ctol dtol atol dim helppoint nxopen dim nullobj nxopen nxobject dim nochain boolean dim createmode nxopen section mode section mode rule circle section dim circl nxopen curvedumbrule workpart scrulefactory createrulebasecurvedumb disk disk circ addtosection circl disk nullobj nullobj helppoint createmode nochain circ addtosection circl disk nullobj nullobj helppoint createmode nochain dim builder workpart feature createextrudebuilder builder section circ define direction extrude dim origin nxopen dim axisz nxopen vector dim updateoption smartobject updateoption dontupdate builder direction workpart direction createdirection origin axisz updateoption builder limit startextend righthandside builder limit endextend righthandside dim peg nxopen feature extrude builder commitfeature builder destroy displayable extrude feature dim body nxopen peg getbodies red body body redisplayobject subend\n",
      "Prediction: [('vb.net',)]\n",
      "True Labels: [('vb.net',)]\n",
      "Post: natural processing library plain english statement ex employee whose age converted employee age provide pointer reference mani\n",
      "Prediction: [()]\n",
      "True Labels: [('java',)]\n",
      "Post: woocommerce review pro mail attachment anybody tell structure behind placeholder thats frontend validate review author priority review author nbsp abbr erforderlich abbr woocommerce wrapper author review author placeholder validate review priority review mail nbsp abbr erforderlich abbr woocommerce wrapper review placeholder come plugin logged require comment registration isset author author woocommerce review pro endif isset mail woocommerce review pro endif endif\n",
      "Prediction: [()]\n",
      "True Labels: [('php',)]\n",
      "Post: uiscrollview uiview positioned uiscrollview halfway storyboard editor appears supposed respond interaction uncheck autolayout storyboard interaction automatically moved alternatively leave autolayout checked viewdidload scrollview translatesautoresizingmaskintoconstraints notecontainer translatesautoresizingmaskintoconstraints nsdictionary viewsdictionary viewsdictionary nsdictionaryofvariablebindings scrollview notecontainer addconstraints nslayoutconstraint constraintswithvisualformat scrollview metric view viewsdictionary addconstraints nslayoutconstraint constraintswithvisualformat scrollview metric view viewsdictionary scrollview addconstraints nslayoutconstraint constraintswithvisualformat notecontainer metric view viewsdictionary scrollview addconstraints nslayoutconstraint constraintswithvisualformat notecontainer metric view viewsdictionary scroll responds interaction automatically moved ridiculously frustrating\n",
      "Prediction: [()]\n",
      "True Labels: [('ios',)]\n",
      "Post: lazyfoo sdl tutorial sdl surface filename temporary storage loaded sdl surface loadedimage optimized sdl surface optimizedimage loadedimage sdl loadbmp filename went loading loadedimage optimized optimizedimage sdl displayformat loadedimage free old sdl freesurface loadedimage optimized optimizedimage optimizedimage scope seeing\n",
      "Prediction: [()]\n",
      "True Labels: [('c++',)]\n",
      "Post: alot system programming apps chance communicate viewed push management projectin proj proj proj proj proj timelog timecommand cmd proj proj timecommand cmd proj proj timelog initial advantage easily readable parsable regex advantage\n",
      "Prediction: [()]\n",
      "True Labels: [('regex', 'xml')]\n",
      "Post: localize master latter practice executing mean developer library imagine paste never\n",
      "Prediction: [()]\n",
      "True Labels: [('javascript',)]\n",
      "Post: built visualbasic assembly vb financial pmt dapr inumberofpayments dloanamount answer namespace assembly recognize formula financial pmt perhaps porting\n",
      "Prediction: [('.net', 'c#', 'vb.net')]\n",
      "True Labels: [('.net', 'asp.net', 'c#', 'vb.net')]\n"
     ]
    }
   ],
   "source": [
    "for index in range(0,10):\n",
    "    print(f'Post: {X_test.iloc[index]}')\n",
    "    print(f'Prediction: {mlb.inverse_transform(np.array([y_pred[index]]))}')\n",
    "    print(f'True Labels: {mlb.inverse_transform(np.array([y_test[index]]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2216df2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Path 'my_model' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_signature\n\u001b[1;32m      3\u001b[0m signature \u001b[38;5;241m=\u001b[39m infer_signature(X_test, y_pred)\n\u001b[0;32m----> 4\u001b[0m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/workspace/machine_learning/PStack/.venv-p5/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:228\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(sk_model, path, conda_env, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    217\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized serialization format: \u001b[39m\u001b[38;5;132;01m{serialization_format}\u001b[39;00m\u001b[38;5;124m. Please specify one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    229\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path), error_code\u001b[38;5;241m=\u001b[39mRESOURCE_ALREADY_EXISTS\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    231\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(path)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mlflow_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mMlflowException\u001b[0m: Path 'my_model' already exists"
     ]
    }
   ],
   "source": [
    "from mlflow.sklearn import save_model\n",
    "from mlflow.models.signature import infer_signature\n",
    "signature = infer_signature(X_test, y_pred)\n",
    "save_model(model, \"my_model\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3526cce",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* Joblib in streamlit\n",
    "\n",
    "## SEE\n",
    "* Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496d06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-p5",
   "language": "python",
   "name": ".venv-p5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
